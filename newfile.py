import streamlit as st
import requests

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="Personal AI", page_icon="üí¨")
st.title("ü§ñ –ú–æ–π –ª–∏—á–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç")

# –°—é–¥–∞ –≤—Å—Ç–∞–≤—å —Å–≤–æ–π —Ç–æ–∫–µ–Ω –∏–ª–∏ –¥–æ–±–∞–≤—å –µ–≥–æ –≤ —Å–µ–∫—Ä–µ—Ç—ã Streamlit
API_TOKEN = "–¢–í–û–ô_–¢–û–ö–ï–ù_–ó–î–ï–°–¨"
MODEL_ID = "mistralai/Mistral-7B-Instruct-v0.3" # –ú–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å
API_URL = f"https://api-inference.huggingface.co/models/{MODEL_ID}"
headers = {"Authorization": f"Bearer {API_TOKEN}"}

def query(payload):
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
if "messages" not in st.session_state:
    st.session_state.messages = []

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–∞—Ç–∞
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# –í–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞
if prompt := st.chat_input("–ù–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("–î—É–º–∞—é..."):
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ API
            output = query({
                "inputs": f"<s>[INST] {prompt} [/INST]",
                "parameters": {"max_new_tokens": 500, "return_full_text": False}
            })
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            if isinstance(output, list) and len(output) > 0:
                answer = output[0].get('generated_text', '–û—à–∏–±–∫–∞ –æ—Ç–≤–µ—Ç–∞')
            else:
                answer = "–ò–ò —Å–µ–π—á–∞—Å –∑–∞–Ω—è—Ç, –ø–æ–ø—Ä–æ–±—É–π —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É."
            
            st.markdown(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})
